{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_preprocessing_tools.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37puETfgRzzg",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoRP98MpR-qj",
        "colab_type": "text"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dFNeLLaj7dz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot  as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopL7tUZSQkT",
        "colab_type": "text"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXkgYY27kf9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv('Data.csv')\n",
        "# factors or independent variables are th params on what we are gonna predicted the dependent variable \n",
        "#usually the last column is the dependent variable\n",
        "\n",
        "x = dataset.iloc[:, :-1].values # :-1 means from zero index to last( index of last one is -1)\n",
        "# iloc stands for locate indexes \n",
        "y= dataset.iloc[:, -1].values   # -1 is index of last column "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmFNQaN3p8dK",
        "colab_type": "code",
        "outputId": "38c4f3bd-a792-4bcb-a4fe-363392d0a736",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNRnyluuqAJc",
        "colab_type": "code",
        "outputId": "e2bdee62-34d4-45a8-b9a4-2aca3991fb54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhfKXNxlSabC",
        "colab_type": "text"
      },
      "source": [
        "## Taking care of missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxd20fmir2GE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.impute import SimpleImputer \n",
        "imputer = SimpleImputer(missing_values=np.nan,strategy='mean') \n",
        "#options are mean, median ,most_frequent,constant\n",
        "imputer.fit(x[:,1:3]) #fit imputer on X \n",
        "#select the columns that have numeric value\n",
        "\n",
        "x[:, 1:3]=imputer.transform(x[:, 1:3])  # fit the imputer on the data \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bTgpWj8tp4z",
        "colab_type": "code",
        "outputId": "0709872f-8428-4c3e-f444-7322c8577ff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrm9LO4UhCeq",
        "colab_type": "text"
      },
      "source": [
        "# **Encoding Categorical Data:**\n",
        "\n",
        "one cloumn with categories , it will be difficult for machine larning model to produce out come for the In dependent variable\n",
        "hence we encode the string to numbers\n",
        "eg: France 0 , germany 1 spain 2\n",
        "\n",
        "But there is not relational order bwteen the countries n we want to prevent it hence we dont do 0 ,1 ,2 \n",
        "\n",
        "Hence we **OneHot Encoding**\n",
        "\n",
        "OneHotEncoding transforms the Country column into 3 columns, similarly 5 countries then 5 columsn\n",
        "\n",
        "it creates **binary vectors** for each country\n",
        "\n",
        "france 100 spain 001 germany 010\n",
        "\n",
        "hence no simple 1 2 3\n",
        "\n",
        "IT IS DONE FOR processing data sets containing **categorical variables**\n",
        "\n",
        "ALso purchased value is Yes and No , so we have to replace it with 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6OUnZNRdVSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(),[0])], remainder='passthrough')\n",
        "#encoder means we want to do encoding , OneHotEncoder is the name of the class that will proceed to do encoding ,0 is the country column\n",
        "#passthrough we want to keep the column that wont be applied transformation i.e Age and Salary\n",
        "\n",
        "x = np.array(ct.fit_transform(x))  # we need the output of the transforamtion as a numpy array for the future transformation\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtP-3tiflll6",
        "colab_type": "code",
        "outputId": "bbd27ee6-c023-4056-cd8e-314853461a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhSpdQWeSsFh",
        "colab_type": "text"
      },
      "source": [
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdkjAtbfmDv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y=le.fit_transform(y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5422uwNMmgMq",
        "colab_type": "code",
        "outputId": "23f6ac95-c594-434b-c0c9-f5f3eef9db8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb_vcgm3qZKW",
        "colab_type": "text"
      },
      "source": [
        "### **Splitting the dataset into the Training set and Test set**\n",
        "\n",
        "The data set is divided into two data sets , training and testing data set\n",
        "\n",
        "Training is used to train the model \n",
        "\n",
        "Testing is used to test the model and evaluating the performance . the test set is not worked during the training\n",
        "\n",
        "we create a pair of matrix \n",
        "xtest , xtrain , ytest , ytrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91A5HQE0n2u9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train ,x_test, y_train , y_test = train_test_split(x,y,test_size=0.2,random_state=1) \n",
        "#test size 20% and \n",
        "#andom_state=1 is Controls the shuffling applied to the data before applying the split. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch7988eIrAym",
        "colab_type": "code",
        "outputId": "bcecb14c-f5b0-4e23-bf47-fd374e00efa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "print(x_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doeR-PmorEzP",
        "colab_type": "code",
        "outputId": "478563e3-7726-4b20-dc7d-39875999aab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(x_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9JytbHLrFJj",
        "colab_type": "code",
        "outputId": "d595aeb7-0d56-404e-9764-d7908819c4cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zSVIcUCrFh8",
        "colab_type": "code",
        "outputId": "a49817c3-5315-4c46-fa11-3d07f204d862",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpGqbS4TqkIR",
        "colab_type": "text"
      },
      "source": [
        "###  **Feature Scaling**\n",
        "\n",
        "Scaling all the variables , so that all considered at the same scale \n",
        "\n",
        "To prevent dominance of one variable  over the other and prevent preference in machine learning model\n",
        "\n",
        "It uses Mean and Standard Deviation\n",
        "\n",
        "Hence to not inlcude the test data set value in the scaling to calcuate Mean and SD , feature scaling is not done before Splitting the data into test and train \n",
        "\n",
        "2 types\n",
        "\n",
        "Standardisation  & Normalisation\n",
        "\n",
        "Here we will use Standardisation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1daMJqzwSfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc= StandardScaler()\n",
        "\n",
        "x_train[:,3:] = sc.fit_transform(x_train[:,3:])\n",
        "\n",
        "x_test[:,3:] = sc.transform(x_test[:,3:])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i4VEmPJ6ExM",
        "colab_type": "code",
        "outputId": "50a592c1-03d7-455e-c107-c5410020c6f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "print(x_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
            " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
            " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
            " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
            " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
            " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
            " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
            " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whS7FDc06FKE",
        "colab_type": "code",
        "outputId": "b381aeb6-e305-4e10-b1d3-f5c9fdcb1ca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(x_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
            " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}